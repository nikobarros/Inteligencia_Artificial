{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c47eb4f",
   "metadata": {},
   "source": [
    "# Proyecto 2 — Pipeline con **RFE** (ULTRA-RÁPIDO)\n",
    "Versión optimizada para tiempo: **CV=2**, grids mínimos, y RFE con pocas opciones.\n",
    "- Mantiene **RFE** en los 4 modelos y **SMOTE dentro de CV** (sin fugas).\n",
    "- Pensado para terminar en ~10–15 minutos en CPU promedio.\n",
    "\n",
    "**Entrada:** `creditcard.csv` en la misma carpeta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993295bb",
   "metadata": {},
   "source": [
    "## 1) Setup e importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65265f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q scikit-learn imbalanced-learn pandas numpy\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e968f2",
   "metadata": {},
   "source": [
    "## 2) Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe6756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cargar_datos(path_csv: str = \"dataset/creditcard.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path_csv)\n",
    "    return df\n",
    "\n",
    "def construir_preprocesador(feature_names):\n",
    "    base_cols = [\"Time\", \"Amount\"]\n",
    "    pca_cols = [c for c in feature_names if c.startswith(\"V\")]\n",
    "    return ColumnTransformer([\n",
    "        (\"robust\", RobustScaler(), base_cols),\n",
    "        (\"std\", StandardScaler(with_mean=False), pca_cols),\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "def metricas_desde_confusion(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn + 1e-12)\n",
    "    sensibilidad = tp / (tp + fn + 1e-12)\n",
    "    especificidad = tn / (tn + fp + 1e-12)\n",
    "    precision = tp / (tp + fp + 1e-12)\n",
    "    f1 = 2 * precision * sensibilidad / (precision + sensibilidad + 1e-12)\n",
    "    return dict(exactitud=acc, sensibilidad=sensibilidad, especificidad=especificidad,\n",
    "                precision=precision, f1=f1, tp=int(tp), fp=int(fp), tn=int(tn), fn=int(fn))\n",
    "\n",
    "def evaluar_modelo(nombre, y_true, y_pred, y_score=None):\n",
    "    print(f\"\\\\n=== {nombre} ===\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Matriz de confusión:\\\\n\", cm)\n",
    "    resumen = metricas_desde_confusion(cm)\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "            resumen[\"roc_auc\"] = auc\n",
    "            print(f\"ROC-AUC: {auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(\"No fue posible calcular ROC-AUC:\", e)\n",
    "    return resumen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effef0d3",
   "metadata": {},
   "source": [
    "## 3) Pipelines con RFE (grids mínimos, CV=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b284fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipeline_knn_rfe(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    rfe_est = LogisticRegression(solver=\"liblinear\", max_iter=200, random_state=RANDOM_STATE)\n",
    "    rfe = RFE(estimator=rfe_est, n_features_to_select=18, step=2)\n",
    "    knn = KNeighborsClassifier()\n",
    "    pipe = ImbPipeline([(\"pre\", pre), (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)), (\"rfe\", rfe), (\"clf\", knn)])\n",
    "    param_grid = {\"rfe__n_features_to_select\": [16, 20], \"clf__n_neighbors\": [5], \"clf__metric\": [\"manhattan\", \"euclidean\"]}\n",
    "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_arbol_rfe(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(random_state=RANDOM_STATE), n_features_to_select=18, step=2)\n",
    "    dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    pipe = ImbPipeline([(\"pre\", pre), (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)), (\"rfe\", rfe), (\"clf\", dt)])\n",
    "    param_grid = {\"rfe__n_features_to_select\": [16, 20], \"clf__max_depth\": [15, None], \"clf__min_samples_leaf\": [1, 2]}\n",
    "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_svm_rfe(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    rfe = RFE(estimator=LinearSVC(random_state=RANDOM_STATE, tol=1e-3, C=1.0), n_features_to_select=18, step=2)\n",
    "    svm = LinearSVC(random_state=RANDOM_STATE)\n",
    "    pipe = ImbPipeline([(\"pre\", pre), (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)), (\"rfe\", rfe), (\"clf\", svm)])\n",
    "    param_grid = {\"rfe__n_features_to_select\": [16, 20], \"clf__C\": [1], \"clf__tol\": [1e-3, 1e-4]}\n",
    "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_rf_rfe(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    rfe = RFE(estimator=RandomForestClassifier(n_estimators=150, random_state=RANDOM_STATE), n_features_to_select=18, step=2)\n",
    "    rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    pipe = ImbPipeline([(\"pre\", pre), (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)), (\"rfe\", rfe), (\"clf\", rf)])\n",
    "    param_grid = {\"rfe__n_features_to_select\": [16, 20], \"clf__n_estimators\": [200], \"clf__max_depth\": [None, 15], \"clf__min_samples_leaf\": [1, 2]}\n",
    "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7a253",
   "metadata": {},
   "source": [
    "## 4) Carga y split 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9f682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraude total: 0.1727% | Train: 0.1725% | Test: 0.1732%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Cargar datos y split ===\n",
    "path_csv = \"dataset/creditcard.csv\"\n",
    "if not os.path.exists(path_csv):\n",
    "    raise FileNotFoundError(\"No se encontró creditcard.csv (Kaggle: mlg-ulb/creditcardfraud).\")\n",
    "df = cargar_datos(path_csv)\n",
    "feature_cols = [\"Time\", \"Amount\"] + [f\"V{i}\" for i in range(1, 29)]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"Class\"].astype(int).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE)\n",
    "print(f\"Fraude total: {y.mean()*100:.4f}% | Train: {y_train.mean()*100:.4f}% | Test: {y_test.mean()*100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954219bb",
   "metadata": {},
   "source": [
    "## 5) Entrenamiento + evaluación + resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf59946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Entrenando k-NN (RFE+LR) ...\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Mejores hiperparámetros (k-NN (RFE+LR)): {'clf__metric': 'manhattan', 'clf__n_neighbors': 5, 'rfe__n_features_to_select': 20}\n",
      "\\n=== k-NN (RFE+LR) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9977    0.9987     85295\n",
      "           1     0.3858    0.8446    0.5297       148\n",
      "\n",
      "    accuracy                         0.9974     85443\n",
      "   macro avg     0.6928    0.9211    0.7642     85443\n",
      "weighted avg     0.9987    0.9974    0.9979     85443\n",
      "\n",
      "Matriz de confusión:\\n [[85096   199]\n",
      " [   23   125]]\n",
      "ROC-AUC: 0.9284\n",
      "\n",
      "================================================================================\n",
      "Entrenando Árbol (RFE+Árbol) ...\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "Mejores hiperparámetros (Árbol (RFE+Árbol)): {'clf__max_depth': None, 'clf__min_samples_leaf': 2, 'rfe__n_features_to_select': 16}\n",
      "\\n=== Árbol (RFE+Árbol) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9978    0.9986     85295\n",
      "           1     0.3584    0.7095    0.4762       148\n",
      "\n",
      "    accuracy                         0.9973     85443\n",
      "   macro avg     0.6789    0.8536    0.7374     85443\n",
      "weighted avg     0.9984    0.9973    0.9977     85443\n",
      "\n",
      "Matriz de confusión:\\n [[85107   188]\n",
      " [   43   105]]\n",
      "ROC-AUC: 0.8703\n",
      "\n",
      "================================================================================\n",
      "Entrenando SVM lineal (RFE+LinearSVC) ...\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Mejores hiperparámetros (SVM lineal (RFE+LinearSVC)): {'clf__C': 1, 'clf__tol': 0.001, 'rfe__n_features_to_select': 16}\n",
      "\\n=== SVM lineal (RFE+LinearSVC) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9809    0.9902     85295\n",
      "           1     0.0729    0.8649    0.1345       148\n",
      "\n",
      "    accuracy                         0.9807     85443\n",
      "   macro avg     0.5363    0.9229    0.5624     85443\n",
      "weighted avg     0.9982    0.9807    0.9888     85443\n",
      "\n",
      "Matriz de confusión:\\n [[83667  1628]\n",
      " [   20   128]]\n",
      "ROC-AUC: 0.9663\n",
      "\n",
      "================================================================================\n",
      "Entrenando Random Forest (RFE+RF) ...\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "Mejores hiperparámetros (Random Forest (RFE+RF)): {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200, 'rfe__n_features_to_select': 20}\n",
      "\\n=== Random Forest (RFE+RF) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9998    0.9997     85295\n",
      "           1     0.8489    0.7973    0.8223       148\n",
      "\n",
      "    accuracy                         0.9994     85443\n",
      "   macro avg     0.9243    0.8985    0.9110     85443\n",
      "weighted avg     0.9994    0.9994    0.9994     85443\n",
      "\n",
      "Matriz de confusión:\\n [[85274    21]\n",
      " [   30   118]]\n",
      "ROC-AUC: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensibilidad</th>\n",
       "      <th>especificidad</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>exactitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM lineal (RFE+LinearSVC)</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.072893</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.980712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-NN (RFE+LR)</th>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.385802</td>\n",
       "      <td>0.529661</td>\n",
       "      <td>0.997402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (RFE+RF)</th>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.999403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Árbol (RFE+Árbol)</th>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.358362</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.997296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sensibilidad especificidad precision        f1  \\\n",
       "SVM lineal (RFE+LinearSVC)     0.864865      0.980913  0.072893  0.134454   \n",
       "k-NN (RFE+LR)                  0.844595      0.997667  0.385802  0.529661   \n",
       "Random Forest (RFE+RF)         0.797297      0.999754  0.848921    0.8223   \n",
       "Árbol (RFE+Árbol)              0.709459      0.997796  0.358362   0.47619   \n",
       "\n",
       "                           exactitud  \n",
       "SVM lineal (RFE+LinearSVC)  0.980712  \n",
       "k-NN (RFE+LR)               0.997402  \n",
       "Random Forest (RFE+RF)      0.999403  \n",
       "Árbol (RFE+Árbol)           0.997296  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV guardado: resumen_metricas_modelos_RFE_ultrafast.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Entrenamiento + GridSearchCV (RFE ULTRA-RÁPIDO) ===\n",
    "modelos = {\n",
    "    \"k-NN (RFE+LR)\": pipeline_knn_rfe(feature_cols),\n",
    "    \"Árbol (RFE+Árbol)\": pipeline_arbol_rfe(feature_cols),\n",
    "    \"SVM lineal (RFE+LinearSVC)\": pipeline_svm_rfe(feature_cols),\n",
    "    \"Random Forest (RFE+RF)\": pipeline_rf_rfe(feature_cols),\n",
    "}\n",
    "resultados = {}\n",
    "for nombre, grid in modelos.items():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Entrenando {nombre} ...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Mejores hiperparámetros ({nombre}): {grid.best_params_}\")\n",
    "    best = grid.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_score = None\n",
    "    if hasattr(best, \"decision_function\"):\n",
    "        try:\n",
    "            y_score = best.decision_function(X_test)\n",
    "        except Exception:\n",
    "            y_score = None\n",
    "    if y_score is None and hasattr(best, \"predict_proba\"):\n",
    "        try:\n",
    "            y_score = best.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            y_score = None\n",
    "    resumen = evaluar_modelo(nombre, y_test, y_pred, y_score)\n",
    "    resultados[nombre] = {\"mejores_hiperparametros\": grid.best_params_, **resumen}\n",
    "\n",
    "import pandas as pd\n",
    "resumen_df = pd.DataFrame(resultados).T[[\"sensibilidad\",\"especificidad\",\"precision\",\"f1\",\"exactitud\"]]\\\n",
    "             .sort_values(by=\"sensibilidad\", ascending=False)\n",
    "display(resumen_df)\n",
    "resumen_df.to_csv(\"resumen_metricas_modelos_RFE_ultrafast.csv\", index=True)\n",
    "print(\"CSV guardado: resumen_metricas_modelos_RFE_ultrafast.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a24314",
   "metadata": {},
   "source": [
    "## 6) (Opcional) Ajuste de umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3025e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuste de umbral a ~0.90 de sensibilidad — threshold=-8.2775\n",
      "\\n=== SVM lineal (RFE+LinearSVC) (umbral ajustado) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     85295\n",
      "           1     0.0017    1.0000    0.0035       148\n",
      "\n",
      "    accuracy                         0.0017     85443\n",
      "   macro avg     0.0009    0.5000    0.0017     85443\n",
      "weighted avg     0.0000    0.0017    0.0000     85443\n",
      "\n",
      "Matriz de confusión:\\n [[    0 85295]\n",
      " [    0   148]]\n",
      "ROC-AUC: 0.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === (Opcional) Ajuste de umbral sobre el modelo con mayor sensibilidad ===\n",
    "mejor_modelo = resumen_df.index[0]\n",
    "best_estimator = modelos[mejor_modelo].best_estimator_\n",
    "if hasattr(best_estimator, \"predict_proba\") or hasattr(best_estimator, \"decision_function\"):\n",
    "    scores = best_estimator.predict_proba(X_test)[:, 1] if hasattr(best_estimator, \"predict_proba\") else best_estimator.decision_function(X_test)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, scores)\n",
    "    objetivo = 0.90\n",
    "    import numpy as np\n",
    "    idx = np.where(recalls >= objetivo)[0]\n",
    "    if len(idx) > 0:\n",
    "        thr = thresholds[idx[0]-1] if idx[0] > 0 else thresholds[0]\n",
    "        y_pred_thr = (scores >= thr).astype(int)\n",
    "        print(f\"Ajuste de umbral a ~{objetivo:.2f} de sensibilidad — threshold={thr:.4f}\")\n",
    "        _ = evaluar_modelo(f\"{mejor_modelo} (umbral ajustado)\", y_test, y_pred_thr, scores)\n",
    "    else:\n",
    "        print(\"No se logró alcanzar la sensibilidad objetivo en test.\")\n",
    "else:\n",
    "    print(\"El mejor modelo no entrega score continuo; se omite ajuste de umbral.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
