{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922d3176",
   "metadata": {},
   "source": [
    "# Detección de transacciones fraudulentas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34308e3a",
   "metadata": {},
   "source": [
    "## Uso de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2acd15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846b8fd",
   "metadata": {},
   "source": [
    "## Entrada y exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f795994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv', dtype={'column_name': 'string'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb3d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset:\n",
      "Dimensiones: (284807, 31)\n",
      "Distribución de clases: Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "Porcentaje de fraude: 0.1727%\n",
      "\n",
      "Valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Información del dataset:\")\n",
    "print(f\"Dimensiones: {df.shape}\")\n",
    "print(f\"Distribución de clases: {df['Class'].value_counts()}\")\n",
    "print(f\"Porcentaje de fraude: {df['Class'].mean()*100:.4f}%\")\n",
    "print(f\"\\nValores nulos: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b831a68",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71eac48",
   "metadata": {},
   "source": [
    "### Escalar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb818ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACIÓN DE COMPONENTES PCA:\n",
      "==================================================\n",
      "V1: Media =   0.0000, Std =   1.9587\n",
      "V2: Media =   0.0000, Std =   1.6513\n",
      "V3: Media =  -0.0000, Std =   1.5163\n",
      "V4: Media =   0.0000, Std =   1.4159\n",
      "V5: Media =   0.0000, Std =   1.3802\n",
      "V6: Media =   0.0000, Std =   1.3323\n",
      "V7: Media =  -0.0000, Std =   1.2371\n",
      "V8: Media =   0.0000, Std =   1.1944\n",
      "V9: Media =  -0.0000, Std =   1.0986\n",
      "V10: Media =   0.0000, Std =   1.0888\n",
      "V11: Media =   0.0000, Std =   1.0207\n",
      "V12: Media =  -0.0000, Std =   0.9992\n",
      "V13: Media =   0.0000, Std =   0.9953\n",
      "V14: Media =   0.0000, Std =   0.9586\n",
      "V15: Media =   0.0000, Std =   0.9153\n",
      "V16: Media =   0.0000, Std =   0.8763\n",
      "V17: Media =  -0.0000, Std =   0.8493\n",
      "V18: Media =   0.0000, Std =   0.8382\n",
      "V19: Media =   0.0000, Std =   0.8140\n",
      "V20: Media =   0.0000, Std =   0.7709\n",
      "V21: Media =   0.0000, Std =   0.7345\n",
      "V22: Media =  -0.0000, Std =   0.7257\n",
      "V23: Media =   0.0000, Std =   0.6245\n",
      "V24: Media =   0.0000, Std =   0.6056\n",
      "V25: Media =   0.0000, Std =   0.5213\n",
      "V26: Media =   0.0000, Std =   0.4822\n",
      "V27: Media =  -0.0000, Std =   0.4036\n",
      "V28: Media =  -0.0000, Std =   0.3301\n"
     ]
    }
   ],
   "source": [
    "columnas_pca = [f'V{i}' for i in range(1, 29)]\n",
    "\n",
    "print(\"VERIFICACIÓN DE COMPONENTES PCA:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in columnas_pca:\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    print(f\"{col}: Media = {media:8.4f}, Std = {std:8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c164e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ESTADÍSTICAS GENERALES PCA:\n",
      "Rango de medias: [-0.0000, 0.0000]\n",
      "Rango de std: [0.3301, 1.9587]\n"
     ]
    }
   ],
   "source": [
    "# Verificación general\n",
    "print(f\"\\nESTADÍSTICAS GENERALES PCA:\")\n",
    "print(f\"Rango de medias: [{df[columnas_pca].mean().min():.4f}, {df[columnas_pca].mean().max():.4f}]\")\n",
    "print(f\"Rango de std: [{df[columnas_pca].std().min():.4f}, {df[columnas_pca].std().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d9582",
   "metadata": {},
   "source": [
    "Dado que las medias son igual a 0, en el caso de las variables PCA, pero sus desviaciones estándar no son iguales, se necesita escalar esos datos sin centrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaa67fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTRATEGIA APLICADA:\n",
      "   - V1-V28: StandardScaler(with_mean=False) → Solo escalar\n",
      "   - Time: RobustScaler → Manejar outliers temporales\n",
      "   - Amount: RobustScaler → Manejar outliers monetarios\n"
     ]
    }
   ],
   "source": [
    "escalado_sin_centrar = StandardScaler(with_mean=False)\n",
    "\n",
    "preprocesador_optimo = ColumnTransformer([\n",
    "    # PCA: Solo escalar, no centrar (ya están centradas)\n",
    "    ('pca_features', escalado_sin_centrar, [f'V{i}' for i in range(1, 29)]),\n",
    "    \n",
    "    # Time y Amount: RobustScaler completo\n",
    "    ('robust_features', RobustScaler(), ['Time', 'Amount'])\n",
    "])\n",
    "\n",
    "print(\"ESTRATEGIA APLICADA:\")\n",
    "print(\"   - V1-V28: StandardScaler(with_mean=False) → Solo escalar\")\n",
    "print(\"   - Time: RobustScaler → Manejar outliers temporales\")  \n",
    "print(\"   - Amount: RobustScaler → Manejar outliers monetarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7ca20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 VERIFICACIÓN POST-ESCALADO:\n",
      "Componentes PCA después del escalado:\n",
      "V1     1.000002\n",
      "V2     1.000002\n",
      "V3     1.000002\n",
      "V4     1.000002\n",
      "V5     1.000002\n",
      "V6     1.000002\n",
      "V7     1.000002\n",
      "V8     1.000002\n",
      "V9     1.000002\n",
      "V10    1.000002\n",
      "V11    1.000002\n",
      "V12    1.000002\n",
      "V13    1.000002\n",
      "V14    1.000002\n",
      "V15    1.000002\n",
      "V16    1.000002\n",
      "V17    1.000002\n",
      "V18    1.000002\n",
      "V19    1.000002\n",
      "V20    1.000002\n",
      "V21    1.000002\n",
      "V22    1.000002\n",
      "V23    1.000002\n",
      "V24    1.000002\n",
      "V25    1.000002\n",
      "V26    1.000002\n",
      "V27    1.000002\n",
      "V28    1.000002\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el preprocesamiento\n",
    "X_escalado = preprocesador_optimo.fit_transform(df.drop('Class', axis=1))\n",
    "\n",
    "# Convertir a DataFrame para verificación\n",
    "columnas_escaladas = [f'V{i}' for i in range(1, 29)] + ['Time', 'Amount']\n",
    "df_verificacion = pd.DataFrame(X_escalado, columns=columnas_escaladas)\n",
    "\n",
    "print(\"📊 VERIFICACIÓN POST-ESCALADO:\")\n",
    "print(\"Componentes PCA después del escalado:\")\n",
    "print(df_verificacion[[f'V{i}' for i in range(1, 29)]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4b879",
   "metadata": {},
   "source": [
    "### Dividir el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff928a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVISIÓN ESTRATIFICADA 70-30:\n",
      "Dataset original - Clase 1: 0.0017%\n",
      "Train - Clase 1: 0.0017%\n",
      "Test - Clase 1: 0.0017%\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"DIVISIÓN ESTRATIFICADA 70-30:\")\n",
    "print(f\"Dataset original - Clase 1: {y.mean():.4f}%\")\n",
    "print(f\"Train - Clase 1: {y_train.mean():.4f}%\")\n",
    "print(f\"Test - Clase 1: {y_test.mean():.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ff2ad",
   "metadata": {},
   "source": [
    "## Balanceo de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1b5605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# aplicar el preprocesamiento\n",
    "X_train_preprocesado = preprocesador_optimo.fit_transform(X_train)\n",
    "X_test_preprocesado = preprocesador_optimo.transform(X_test)\n",
    "\n",
    "# se aplica SMOTE solo al conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_preprocesado, y_train)\n",
    "\n",
    "y_train_balanced.value_counts()\n",
    "\n",
    "#\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "import numpy as np\n",
    "\n",
    "def to_dense(X):\n",
    "    from scipy.sparse import issparse\n",
    "    return X.toarray() if issparse(X) else X\n",
    "\n",
    "Xtr_bal = to_dense(X_train_balanced)          # <-- este es el correcto para fit de RFE/RFECV\n",
    "Xte      = to_dense(X_test_preprocesado)      # test NO se resamplea\n",
    "\n",
    "# Si necesitas nombres de columnas del preprocesador:\n",
    "try:\n",
    "    feature_names = preprocesador_optimo.get_feature_names_out()\n",
    "except Exception:\n",
    "    feature_names = np.array([f\"f{i}\" for i in range(Xtr_bal.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8de9cc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     60\u001b[39m rfecv_dt = RFECV(\n\u001b[32m     61\u001b[39m     estimator=dt_base,\n\u001b[32m     62\u001b[39m     step=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# ✅ Ajusta con datos balanceados\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mrfecv_dt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_balanced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Transforma tanto train balanceado como test original\u001b[39;00m\n\u001b[32m     72\u001b[39m X_train_sel_dt = rfecv_dt.transform(Xtr_bal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     66\u001b[39m args_msg = [\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     69\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:897\u001b[39m, in \u001b[36mRFECV.fit\u001b[39m\u001b[34m(self, X, y, groups, **params)\u001b[39m\n\u001b[32m    894\u001b[39m     parallel = Parallel(n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m    895\u001b[39m     func = delayed(_rfe_single_fit)\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m step_results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m scores, supports, rankings, step_n_features = \u001b[38;5;28mzip\u001b[39m(*step_results)\n\u001b[32m    903\u001b[39m step_n_features_rev = np.array(step_n_features[\u001b[32m0\u001b[39m])[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\none\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Selección de características por modelo + evaluación\n",
    "# =========================\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE, RFECV, SequentialFeatureSelector, SelectKBest, mutual_info_classif\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC  # SVM lineal con coef_, apto para RFE\n",
    "\n",
    "# --- Utilidades ---\n",
    "def to_dense(X):\n",
    "    return X.toarray() if issparse(X) else X\n",
    "\n",
    "def get_feature_names(preprocesador, n_cols):\n",
    "    try:\n",
    "        return preprocesador.get_feature_names_out()\n",
    "    except Exception:\n",
    "        return np.array([f\"f{i}\" for i in range(n_cols)])\n",
    "\n",
    "def evaluar_modelo(nombre, clf, X_tr, y_tr, X_te, y_te, proba_ok=True):\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_te)\n",
    "\n",
    "    print(f\"\\n===== {nombre} =====\")\n",
    "    print(classification_report(y_te, y_pred, digits=4))\n",
    "    # ROC-AUC si el clasificador tiene predict_proba o decision_function\n",
    "    auc = None\n",
    "    if proba_ok and hasattr(clf, \"predict_proba\"):\n",
    "        y_proba = clf.predict_proba(X_te)[:, 1]\n",
    "        auc = roc_auc_score(y_te, y_proba)\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        y_scores = clf.decision_function(X_te)\n",
    "        auc = roc_auc_score(y_te, y_scores)\n",
    "    if auc is not None:\n",
    "        print(\"ROC-AUC:\", round(auc, 4))\n",
    "    return clf\n",
    "\n",
    "# Densificar si hace falta (RFE y SFS suelen requerir matrices densas)\n",
    "Xtr = to_dense(X_train_preprocesado)\n",
    "Xte = to_dense(X_test_preprocesado)\n",
    "feature_names = get_feature_names(preprocesador_optimo, Xtr.shape[1])\n",
    "\n",
    "# CV común\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "dt_base = DecisionTreeClassifier(random_state=42)\n",
    "rfecv_dt = RFECV(\n",
    "    estimator=dt_base,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ✅ Ajusta con datos balanceados\n",
    "rfecv_dt.fit(Xtr_bal, y_train_balanced)\n",
    "\n",
    "# Transforma tanto train balanceado como test original\n",
    "X_train_sel_dt = rfecv_dt.transform(Xtr_bal)\n",
    "X_test_sel_dt  = rfecv_dt.transform(Xte)\n",
    "\n",
    "mask_dt = rfecv_dt.support_\n",
    "sel_names_dt = feature_names[mask_dt]\n",
    "print(\"DT - #features:\", mask_dt.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693462f",
   "metadata": {},
   "source": [
    "## Selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 2) Random Forest + RFE/RFECV ===============\n",
    "rf_base = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "rfecv_rf = RFECV(\n",
    "    estimator=rf_base,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv_rf.fit(Xtr, y_train_balanced)\n",
    "mask_rf = rfecv_rf.support_\n",
    "sel_names_rf = feature_names[mask_rf]\n",
    "print(\"\\n[Random Forest] Nº features seleccionadas:\", mask_rf.sum())\n",
    "print(\"Algunas features:\", list(sel_names_rf[:20]))\n",
    "Xtr_rf = rfecv_rf.transform(Xtr)\n",
    "Xte_rf = rfecv_rf.transform(Xte)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "clf_rf = evaluar_modelo(\"Random Forest (con RFE)\", clf_rf, Xtr_rf, y_train_balanced, Xte_rf, y_test, proba_ok=True)\n",
    "resultados[\"RandomForest\"] = {\"n_features\": mask_rf.sum(), \"features\": sel_names_rf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 3) SVM (lineal) + RFE/RFECV ===============\n",
    "# Usamos LinearSVC (tiene coef_) -> apto para RFE; más estable que SVC(kernel='linear') en high-dim\n",
    "svm_base = LinearSVC(C=1.0, random_state=42)\n",
    "rfecv_svm = RFECV(\n",
    "    estimator=svm_base,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv_svm.fit(Xtr, y_train_balanced)\n",
    "mask_svm = rfecv_svm.support_\n",
    "sel_names_svm = feature_names[mask_svm]\n",
    "print(\"\\n[SVM lineal] Nº features seleccionadas:\", mask_svm.sum())\n",
    "print(\"Algunas features:\", list(sel_names_svm[:20]))\n",
    "Xtr_svm = rfecv_svm.transform(Xtr)\n",
    "Xte_svm = rfecv_svm.transform(Xte)\n",
    "\n",
    "# Nota: LinearSVC no expone predict_proba; usamos decision_function para AUC\n",
    "clf_svm = LinearSVC(C=1.0, random_state=42)\n",
    "clf_svm = evaluar_modelo(\"SVM lineal (con RFE)\", clf_svm, Xtr_svm, y_train_balanced, Xte_svm, y_test, proba_ok=False)\n",
    "resultados[\"SVM_linear\"] = {\"n_features\": mask_svm.sum(), \"features\": sel_names_svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e228e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 4) k-NN (NO soporta RFE) ===============\n",
    "# Alternativa A (wrapper): Sequential Forward Selector con kNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sfs_knn = SequentialFeatureSelector(\n",
    "    estimator=knn,\n",
    "    n_features_to_select=min(30, Xtr.shape[1]),  # ajusta este número\n",
    "    direction=\"forward\",\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs_knn.fit(Xtr, y_train_balanced)\n",
    "mask_knn = sfs_knn.get_support()\n",
    "sel_names_knn = feature_names[mask_knn]\n",
    "print(\"\\n[k-NN] (SFS) Nº features seleccionadas:\", mask_knn.sum())\n",
    "print(\"Algunas features:\", list(sel_names_knn[:20]))\n",
    "Xtr_knn = sfs_knn.transform(Xtr)\n",
    "Xte_knn = sfs_knn.transform(Xte)\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_knn = evaluar_modelo(\"k-NN (con SFS, alternativa a RFE)\", clf_knn, Xtr_knn, y_train_balanced, Xte_knn, y_test, proba_ok=False)\n",
    "resultados[\"kNN_SFS\"] = {\"n_features\": mask_knn.sum(), \"features\": sel_names_knn}\n",
    "\n",
    "# Alternativa B (filter): si prefieres algo más rápido para kNN, comenta SFS y usa SelectKBest:\n",
    "# kbest = SelectKBest(mutual_info_classif, k=30)\n",
    "# Xtr_knn = kbest.fit_transform(Xtr, y_train_balanced)\n",
    "# Xte_knn = kbest.transform(Xte)\n",
    "# mask_knn = kbest.get_support()\n",
    "# sel_names_knn = feature_names[mask_knn]\n",
    "# clf_knn = evaluar_modelo(\"k-NN (SelectKBest)\", KNeighborsClassifier(n_neighbors=5),\n",
    "#                          Xtr_knn, y_train_balanced, Xte_knn, y_test, proba_ok=False)\n",
    "# resultados[\"kNN_KBest\"] = {\"n_features\": mask_knn.sum(), \"features\": sel_names_knn}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a177c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Resumen final ===============\n",
    "print(\"\\n================ RESUMEN SELECCIÓN ================\")\n",
    "for k, v in resultados.items():\n",
    "    print(f\"{k}: {v['n_features']} features seleccionadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c98d6",
   "metadata": {},
   "source": [
    "## Entrenamiento de clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dfe89",
   "metadata": {},
   "source": [
    "## Búsqueda y selección de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb17374",
   "metadata": {},
   "source": [
    "## Evaluar el desempeño de los modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
