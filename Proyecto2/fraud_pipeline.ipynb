{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b6edba8",
   "metadata": {},
   "source": [
    "# Proyecto 2 — Detección de Fraude (Pipeline Completo)\n",
    "Notebook generado con preprocesamiento, SMOTE en CV, selección de características, búsqueda de hiperparámetros y evaluación.\n",
    "\n",
    "**Requisitos**: `scikit-learn>=1.2`, `imbalanced-learn`, `pandas`, `numpy`.\n",
    "\n",
    "**Entrada**: `creditcard.csv` (Kaggle: mlg-ulb/creditcardfraud) ubicado junto al notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21545ec6",
   "metadata": {},
   "source": [
    "## 1) Setup e importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbe98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q scikit-learn imbalanced-learn pandas numpy\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFECV, SelectKBest, mutual_info_classif, SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600f5e1",
   "metadata": {},
   "source": [
    "## 2) Utilidades (métricas, evaluación, preprocesador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c41a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cargar_datos(path_csv: str = \"dataset/creditcard.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path_csv)\n",
    "    return df\n",
    "\n",
    "def construir_preprocesador(feature_names):\n",
    "    base_cols = [\"Time\", \"Amount\"]\n",
    "    pca_cols = [c for c in feature_names if c.startswith(\"V\")]\n",
    "    return ColumnTransformer([\n",
    "        (\"robust\", RobustScaler(), base_cols),\n",
    "        (\"std\", StandardScaler(with_mean=False), pca_cols),\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "def metricas_desde_confusion(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn + 1e-12)\n",
    "    sensibilidad = tp / (tp + fn + 1e-12)\n",
    "    especificidad = tn / (tn + fp + 1e-12)\n",
    "    precision = tp / (tp + fp + 1e-12)\n",
    "    f1 = 2 * precision * sensibilidad / (precision + sensibilidad + 1e-12)\n",
    "    return dict(exactitud=acc, sensibilidad=sensibilidad, especificidad=especificidad,\n",
    "                precision=precision, f1=f1, tp=int(tp), fp=int(fp), tn=int(tn), fn=int(fn))\n",
    "\n",
    "def evaluar_modelo(nombre, y_true, y_pred, y_score=None):\n",
    "    print(f\"\\\\n=== {nombre} ===\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Matriz de confusión:\\\\n\", cm)\n",
    "    resumen = metricas_desde_confusion(cm)\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "            resumen[\"roc_auc\"] = auc\n",
    "            print(f\"ROC-AUC: {auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(\"No fue posible calcular ROC-AUC:\", e)\n",
    "    return resumen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb3114",
   "metadata": {},
   "source": [
    "## 3) Pipelines con selección de características + GridSearchCV (SMOTE en CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f390163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline_knn(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    knn = KNeighborsClassifier()\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        estimator=KNeighborsClassifier(n_neighbors=5),\n",
    "        n_features_to_select=15,\n",
    "        direction=\"forward\",\n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pipe = ImbPipeline([(\"pre\", pre),\n",
    "                        (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "                        (\"sfs\", sfs),\n",
    "                        (\"clf\", knn)])\n",
    "    param_grid = {\"clf__n_neighbors\": [3,5,7,9,11],\n",
    "                  \"clf__metric\": [\"euclidean\", \"manhattan\"]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_arbol(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    rfecv = RFECV(estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "                  step=2, min_features_to_select=10, scoring=\"f1\", cv=3, n_jobs=-1)\n",
    "    pipe = ImbPipeline([(\"pre\", pre),\n",
    "                        (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "                        (\"rfecv\", rfecv),\n",
    "                        (\"clf\", dt)])\n",
    "    param_grid = {\"clf__max_depth\":[5,10,15,20,None],\n",
    "                  \"clf__min_samples_split\":[2,5,10],\n",
    "                  \"clf__min_samples_leaf\":[1,2,4]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_svm(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=20)\n",
    "    svm = LinearSVC(random_state=RANDOM_STATE)\n",
    "    pipe = ImbPipeline([(\"pre\", pre),\n",
    "                        (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "                        (\"sel\", selector),\n",
    "                        (\"clf\", svm)])\n",
    "    param_grid = {\"clf__C\":[0.1,1,10],\n",
    "                  \"clf__tol\":[1e-3,1e-4],\n",
    "                  \"sel__k\":[15,20,25]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "def pipeline_rf(feature_names):\n",
    "    pre = construir_preprocesador(feature_names)\n",
    "    sfm = SelectFromModel(RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "                          threshold=\"median\")\n",
    "    rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    pipe = ImbPipeline([(\"pre\", pre),\n",
    "                        (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "                        (\"sel\", sfm),\n",
    "                        (\"clf\", rf)])\n",
    "    param_grid = {\"clf__n_estimators\":[200,400,600],\n",
    "                  \"clf__max_depth\":[None,10,15,20],\n",
    "                  \"clf__min_samples_leaf\":[1,2,4]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    return GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1, refit=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97cf08d",
   "metadata": {},
   "source": [
    "## 4) Carga de datos y split 70/30 estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06c04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraude total: 0.1727% | Train: 0.1725% | Test: 0.1732%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Cargar datos ===\n",
    "path_csv = \"dataset/creditcard.csv\"  # Ajusta si tu archivo está en otra ruta\n",
    "if not os.path.exists(path_csv):\n",
    "    raise FileNotFoundError(\"No se encontró creditcard.csv. Descárgalo de Kaggle (mlg-ulb/creditcardfraud).\")\n",
    "\n",
    "df = cargar_datos(path_csv)\n",
    "feature_cols = [\"Time\", \"Amount\"] + [f\"V{i}\" for i in range(1, 29)]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"Class\"].astype(int).values\n",
    "\n",
    "# Split 70/30 estratificado\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Fraude total: {y.mean()*100:.4f}% | Train: {y_train.mean()*100:.4f}% | Test: {y_test.mean()*100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22202eb4",
   "metadata": {},
   "source": [
    "## 5) Entrenamiento + evaluación + resumen comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12773ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Entrenando k-NN + GridSearchCV ...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Entrenar modelos con GridSearchCV ===\n",
    "modelos = {\n",
    "    \"k-NN\": pipeline_knn(feature_cols),\n",
    "    \"Árbol de Decisión\": pipeline_arbol(feature_cols),\n",
    "    \"SVM (LinearSVC)\": pipeline_svm(feature_cols),\n",
    "    \"Random Forest\": pipeline_rf(feature_cols),\n",
    "}\n",
    "resultados = {}\n",
    "\n",
    "for nombre, grid in modelos.items():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Entrenando {nombre} + GridSearchCV ...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Mejores hiperparámetros ({nombre}): {grid.best_params_}\")\n",
    "    best = grid.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    y_score = None\n",
    "    if hasattr(best, \"decision_function\"):\n",
    "        try:\n",
    "            y_score = best.decision_function(X_test)\n",
    "        except Exception:\n",
    "            y_score = None\n",
    "    if y_score is None and hasattr(best, \"predict_proba\"):\n",
    "        try:                                                                                            \n",
    "            y_score = best.predict_proba(X_test)[:, 1]\n",
    "        except Exception:\n",
    "            y_score = None\n",
    "\n",
    "    resumen = evaluar_modelo(nombre, y_test, y_pred, y_score)\n",
    "    resultados[nombre] = {\"mejores_hiperparametros\": grid.best_params_, **resumen}\n",
    "\n",
    "import pandas as pd\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"RESUMEN COMPARATIVO (métricas clave)\")\n",
    "resumen_df = pd.DataFrame(resultados).T[\n",
    "    [\"sensibilidad\", \"especificidad\", \"precision\", \"f1\", \"exactitud\"]\n",
    "].sort_values(by=\"sensibilidad\", ascending=False)\n",
    "display(resumen_df)\n",
    "resumen_df.to_csv(\"resumen_metricas_modelos.csv\", index=True)\n",
    "print(\"CSV guardado: resumen_metricas_modelos.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d45434",
   "metadata": {},
   "source": [
    "## 6) (Opcional) Ajuste de umbral sobre el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb770bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === (Opcional) Ajuste de umbral en el modelo con mayor sensibilidad ===\n",
    "mejor_modelo = resumen_df.index[0]\n",
    "best_estimator = modelos[mejor_modelo].best_estimator_\n",
    "\n",
    "if hasattr(best_estimator, \"predict_proba\") or hasattr(best_estimator, \"decision_function\"):\n",
    "    scores = best_estimator.predict_proba(X_test)[:, 1] if hasattr(best_estimator, \"predict_proba\") else best_estimator.decision_function(X_test)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, scores)\n",
    "    objetivo = 0.90\n",
    "    idx = np.where(recalls >= objetivo)[0]\n",
    "    if len(idx) > 0:\n",
    "        thr = thresholds[idx[0]-1] if idx[0] > 0 else thresholds[0]\n",
    "        y_pred_thr = (scores >= thr).astype(int)\n",
    "        print(f\"Ajuste de umbral para ~{objetivo:.2f} de sensibilidad — threshold={thr:.4f}\")\n",
    "        _ = evaluar_modelo(f\"{mejor_modelo} (umbral ajustado)\", y_test, y_pred_thr, scores)\n",
    "    else:\n",
    "        print(\"No se encontró un umbral que alcance la sensibilidad objetivo en test.\")\n",
    "else:\n",
    "    print(\"El mejor modelo no expone score continuo; se omite ajuste de umbral.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
